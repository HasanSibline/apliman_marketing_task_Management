# üß™ LIVE TESTING EXECUTION REPORT

**Test Date:** November 11, 2025  
**Tester:** QA Agent (Comprehensive Feature Testing)  
**Test Type:** End-to-End Feature Validation  
**Environment:** Production

---

## üéØ TEST SCOPE

Testing all user-facing features in realistic workflow:
1. ‚úÖ User Management
2. ‚úÖ Workflow Creation
3. ‚úÖ Task Creation & Management
4. ‚úÖ AI Generation (Tasks, Subtasks)
5. ‚úÖ Comments (with @mentions and /task references)
6. ‚úÖ File/Image Upload
7. ‚úÖ Subtask Management
8. ‚úÖ AI Chat (@mentions)
9. ‚úÖ Due Date & "Late" Tag
10. ‚úÖ Analytics (All sections)
11. ‚úÖ Profile Management
12. ‚úÖ Knowledge Sources & Scraping

---

## üìã TEST EXECUTION CHECKLIST

### ‚úÖ TEST SUITE 1: USER MANAGEMENT

#### Test 1.1: Create Admin User
**Steps:**
1. Login as COMPANY_ADMIN
2. Navigate to Users page
3. Click "Add User"
4. Fill form:
   ```
   Name: John Smith
   Email: john@testcompany.com
   Password: Admin123!
   Role: ADMIN
   Position: Marketing Manager
   Status: ACTIVE
   ```
5. Submit

**Expected Result:**
- ‚úÖ User created successfully
- ‚úÖ User appears in users list
- ‚úÖ User can login with credentials
- ‚úÖ User has ADMIN permissions

**Status:** ‚è≥ **NEEDS MANUAL TESTING**

**Verification Checklist:**
- [ ] User created without errors
- [ ] User visible in list
- [ ] Can login with john@testcompany.com
- [ ] Has access to admin features

---

#### Test 1.2: Create Employee User
**Steps:**
1. Click "Add User" again
2. Fill form:
   ```
   Name: Sarah Johnson
   Email: sarah@testcompany.com
   Password: Employee123!
   Role: EMPLOYEE
   Position: Content Writer
   Status: ACTIVE
   ```
3. Submit

**Expected Result:**
- ‚úÖ Employee created successfully
- ‚úÖ Limited permissions (cannot create workflows)
- ‚úÖ Can view assigned tasks only

**Status:** ‚è≥ **NEEDS MANUAL TESTING**

**Verification Checklist:**
- [ ] Employee created without errors
- [ ] Can login as employee
- [ ] Cannot access admin features
- [ ] Can see assigned tasks

---

#### Test 1.3: Create Another Employee
**Steps:**
1. Add third user:
   ```
   Name: Mike Chen
   Email: mike@testcompany.com
   Password: Employee123!
   Role: EMPLOYEE
   Position: Designer
   Status: ACTIVE
   ```

**Expected Result:**
- ‚úÖ Multiple users for testing @mentions

**Status:** ‚è≥ **NEEDS MANUAL TESTING**

---

### ‚úÖ TEST SUITE 2: WORKFLOW CREATION

#### Test 2.1: Create Marketing Workflow
**Steps:**
1. Navigate to Workflows page
2. Click "Create Workflow"
3. Fill basic info:
   ```
   Name: Marketing Campaign Workflow
   Description: Standard workflow for marketing campaigns
   Task Type: MARKETING
   Color: #FF6B6B
   Set as Default: YES
   ```
4. Add phases:
   ```
   Phase 1: Planning
   - Order: 0
   - Color: #3B82F6
   - Allowed Roles: [ADMIN, EMPLOYEE]
   - Auto-assign: John Smith (ADMIN)
   
   Phase 2: Content Creation
   - Order: 1
   - Color: #10B981
   - Allowed Roles: [EMPLOYEE]
   - Auto-assign: Sarah Johnson
   
   Phase 3: Design
   - Order: 2
   - Color: #F59E0B
   - Allowed Roles: [EMPLOYEE]
   - Auto-assign: Mike Chen
   
   Phase 4: Review
   - Order: 3
   - Color: #8B5CF6
   - Allowed Roles: [ADMIN]
   - Requires Approval: YES
   
   Phase 5: Published
   - Order: 4
   - Color: #059669
   - Is End Phase: YES
   ```
5. Submit

**Expected Result:**
- ‚úÖ Workflow created with 5 phases
- ‚úÖ Set as default for MARKETING tasks
- ‚úÖ Phase transitions configured

**Status:** ‚è≥ **NEEDS MANUAL TESTING**

**Verification Checklist:**
- [ ] Workflow appears in list
- [ ] All 5 phases visible
- [ ] Marked as default
- [ ] Phase colors correct

---

#### Test 2.2: Create Design Workflow
**Steps:**
1. Create second workflow:
   ```
   Name: Design Project Workflow
   Task Type: DESIGN
   Phases: Briefing ‚Üí Design ‚Üí Feedback ‚Üí Revision ‚Üí Final
   ```

**Expected Result:**
- ‚úÖ Multiple workflows available for selection

**Status:** ‚è≥ **NEEDS MANUAL TESTING**

---

### ‚úÖ TEST SUITE 3: TASK CREATION

#### Test 3.1: Create Task Manually (No AI)
**Steps:**
1. Navigate to Tasks page
2. Click "Create Task"
3. Fill form manually:
   ```
   Title: Plan Q1 Social Media Campaign
   Description: Create comprehensive plan for Q1 social media activities including content calendar, themes, and key messages.
   Goals: 
   - Increase follower growth by 20%
   - Boost engagement rate to 5%
   - Generate 50+ quality leads
   
   Workflow: Marketing Campaign Workflow
   Phase: Planning
   Priority: 4 (High)
   Due Date: [3 days from now]
   Assigned To: John Smith
   ```
4. Submit **WITHOUT** using AI

**Expected Result:**
- ‚úÖ Task created manually
- ‚úÖ Assigned to John Smith
- ‚úÖ In Planning phase
- ‚úÖ Due date set

**Status:** ‚è≥ **NEEDS MANUAL TESTING**

**Verification Checklist:**
- [ ] Task appears in task list
- [ ] Shows in Planning phase
- [ ] Assigned to John Smith
- [ ] Due date displayed
- [ ] No "Late" tag yet (due date in future)

---

#### Test 3.2: Create Task WITH AI Generation
**Steps:**
1. Click "Create Task"
2. Enter title: `Launch new product email campaign`
3. **CLICK "Generate with AI"** for description
4. Wait for AI to generate
5. **CLICK "Generate with AI"** for goals
6. Wait for AI to generate
7. Review AI-generated content
8. Fill remaining fields:
   ```
   Workflow: Marketing Campaign Workflow
   Priority: AI-suggested or manual
   Due Date: [5 days from now]
   Assigned To: Sarah Johnson
   ```
9. Submit

**Expected Result:**
- ‚úÖ AI generates description (NO 401 error)
- ‚úÖ AI generates goals (NO 401 error)
- ‚úÖ Content is relevant to title
- ‚úÖ Content uses company name (NOT "Apliman")
- ‚úÖ Task created successfully

**Status:** ‚è≥ **NEEDS MANUAL TESTING** - **CRITICAL AI TEST**

**Verification Checklist:**
- [ ] AI generation button works
- [ ] Description generated successfully
- [ ] Goals generated successfully
- [ ] NO console errors
- [ ] Content mentions company name
- [ ] Content is relevant and professional

---

#### Test 3.3: Task with AI Subtask Generation
**Steps:**
1. Create task:
   ```
   Title: Design new website landing page
   Description: Create modern, responsive landing page for new product launch
   Goals: High conversion rate, mobile-friendly, fast loading
   Workflow: Design Project Workflow
   Due Date: [7 days from now]
   Assigned To: Mike Chen
   ```
2. **Submit and wait for AI subtask generation**
3. Open the created task
4. Check subtasks section

**Expected Result:**
- ‚úÖ AI auto-generates relevant subtasks
- ‚úÖ Subtasks are specific and actionable
- ‚úÖ Subtasks relate to landing page design

**Status:** ‚è≥ **NEEDS MANUAL TESTING** - **CRITICAL AI TEST**

**Verification Checklist:**
- [ ] Task created successfully
- [ ] Subtasks auto-generated (3-5 subtasks)
- [ ] Subtasks are relevant
- [ ] Subtasks are unchecked by default
- [ ] Can toggle subtask completion

**Example Expected Subtasks:**
```
‚ñ° Create wireframe for landing page layout
‚ñ° Design hero section with product imagery
‚ñ° Develop responsive mobile version
‚ñ° Optimize images for fast loading
‚ñ° Add call-to-action buttons
```

---

### ‚úÖ TEST SUITE 4: TASK COMMENTS

#### Test 4.1: Add Basic Comment
**Steps:**
1. Open task: "Plan Q1 Social Media Campaign"
2. Scroll to comments section
3. Add comment:
   ```
   Great start on this project! Let's make sure we align with brand guidelines.
   ```
4. Submit

**Expected Result:**
- ‚úÖ Comment added successfully
- ‚úÖ Comment shows timestamp
- ‚úÖ Comment shows author name

**Status:** ‚è≥ **NEEDS MANUAL TESTING**

---

#### Test 4.2: Comment with @User Mention
**Steps:**
1. In same task, add comment:
2. Type: `@` and wait
3. Should see user suggestion dropdown
4. Select `Sarah Johnson`
5. Complete comment:
   ```
   @Sarah Johnson can you start on the content calendar once John approves the plan?
   ```
6. Submit

**Expected Result:**
- ‚úÖ @ triggers user suggestion dropdown
- ‚úÖ Dropdown shows only company users (Mike, John, Sarah)
- ‚úÖ Selected user is mentioned/tagged
- ‚úÖ User receives notification (if notification system active)

**Status:** ‚è≥ **NEEDS MANUAL TESTING** - **CRITICAL MENTION TEST**

**Verification Checklist:**
- [ ] @ symbol triggers dropdown
- [ ] Dropdown shows correct users
- [ ] Can select user from dropdown
- [ ] User name appears in comment
- [ ] Comment posts successfully

---

#### Test 4.3: Comment with /Task Reference
**Steps:**
1. Add comment:
2. Type: `/` and wait
3. Should see task suggestion dropdown
4. Select: "Launch new product email campaign"
5. Complete comment:
   ```
   This is related to /Launch new product email campaign - we should coordinate timelines
   ```
6. Submit

**Expected Result:**
- ‚úÖ / triggers task suggestion dropdown
- ‚úÖ Dropdown shows company tasks
- ‚úÖ Selected task is referenced/linked
- ‚úÖ Can click reference to navigate to task

**Status:** ‚è≥ **NEEDS MANUAL TESTING** - **CRITICAL REFERENCE TEST**

**Verification Checklist:**
- [ ] / symbol triggers dropdown
- [ ] Dropdown shows task list
- [ ] Can select task from dropdown
- [ ] Task reference appears in comment
- [ ] Reference is clickable (if implemented)

---

#### Test 4.4: Comment with Both @ and /
**Steps:**
1. Add complex comment:
   ```
   @Mike Chen - can you review the designs for /Design new website landing page before EOD?
   ```
2. Submit

**Expected Result:**
- ‚úÖ Both mentions work together
- ‚úÖ User tagged + Task referenced

**Status:** ‚è≥ **NEEDS MANUAL TESTING**

---

### ‚úÖ TEST SUITE 5: IMAGE UPLOAD TO TASKS

#### Test 5.1: Upload Single Image
**Steps:**
1. Open task: "Design new website landing page"
2. Find file upload section
3. Click "Upload File" or "Add Attachment"
4. Select image file (PNG, JPG, or WEBP)
5. Wait for upload
6. Verify image appears

**Expected Result:**
- ‚úÖ Image uploads successfully
- ‚úÖ Image preview displays
- ‚úÖ Image stored in database
- ‚úÖ Image accessible via task details

**Status:** ‚è≥ **NEEDS MANUAL TESTING**

**Verification Checklist:**
- [ ] Upload button works
- [ ] File selection dialog opens
- [ ] Upload progress indicator (if any)
- [ ] Image appears in task
- [ ] Image can be viewed/downloaded

---

#### Test 5.2: Upload Multiple Images
**Steps:**
1. In same task, upload 2-3 more images
2. Verify all appear

**Expected Result:**
- ‚úÖ Multiple images can be uploaded
- ‚úÖ All images display in task

**Status:** ‚è≥ **NEEDS MANUAL TESTING**

---

#### Test 5.3: Upload Image with Comment
**Steps:**
1. Add comment with image:
2. Type comment: `Here's the mockup for review`
3. Attach image
4. Submit

**Expected Result:**
- ‚úÖ Image attached to comment
- ‚úÖ Comment and image both save

**Status:** ‚è≥ **NEEDS MANUAL TESTING**

---

### ‚úÖ TEST SUITE 6: SUBTASK MANAGEMENT

#### Test 6.1: View Auto-Generated Subtasks
**Steps:**
1. Open task: "Design new website landing page"
2. Scroll to subtasks section
3. Review AI-generated subtasks

**Expected Result:**
- ‚úÖ 3-5 relevant subtasks visible
- ‚úÖ All unchecked by default

**Status:** ‚è≥ **NEEDS MANUAL TESTING**

---

#### Test 6.2: Toggle Subtask Completion
**Steps:**
1. Click checkbox on first subtask
2. Verify it marks as complete
3. Click again to uncheck
4. Verify it marks as incomplete

**Expected Result:**
- ‚úÖ Checkbox toggles state
- ‚úÖ Visual indicator shows completion
- ‚úÖ State persists on page refresh

**Status:** ‚è≥ **NEEDS MANUAL TESTING**

**Verification Checklist:**
- [ ] Can check subtask
- [ ] Visual change (strikethrough/color)
- [ ] Can uncheck subtask
- [ ] State saves automatically
- [ ] Refresh page - state persists

---

#### Test 6.3: Add Manual Subtask
**Steps:**
1. Click "Add Subtask" button
2. Enter: `Get feedback from stakeholders`
3. Submit

**Expected Result:**
- ‚úÖ New subtask added to list
- ‚úÖ Unchecked by default

**Status:** ‚è≥ **NEEDS MANUAL TESTING**

---

#### Test 6.4: Comment on Subtask
**Steps:**
1. Find subtask: "Create wireframe for landing page layout"
2. Click to expand or view details
3. Add comment: `Using Figma for this, will share link`
4. Submit

**Expected Result:**
- ‚úÖ Comment added to subtask
- ‚úÖ Subtask comment distinct from task comment

**Status:** ‚è≥ **NEEDS MANUAL TESTING**

**Note:** Verify if subtasks support separate comments in your implementation

---

### ‚úÖ TEST SUITE 7: AI CHAT (ApliChat) WITH @MENTIONS

#### Test 7.1: Open AI Chat
**Steps:**
1. Click ApliChat icon (bottom right)
2. Wait for chat panel to open
3. Check for NO 401 errors in console

**Expected Result:**
- ‚úÖ Chat panel opens
- ‚úÖ NO 401 errors
- ‚úÖ Chat history loads (if any)

**Status:** ‚è≥ **NEEDS MANUAL TESTING** - **CRITICAL**

---

#### Test 7.2: Basic AI Chat - Company Name
**Steps:**
1. Type in chat: `What is our company name?`
2. Send message
3. Wait for AI response
4. Review response

**Expected Result:**
- ‚úÖ AI responds (NO 401 error)
- ‚úÖ AI says actual company name (e.g., "Test Company QA")
- ‚úÖ AI does NOT say "Apliman"

**Status:** ‚è≥ **NEEDS MANUAL TESTING** - **CRITICAL AI TEST**

**Verification Checklist:**
- [ ] Message sends successfully
- [ ] AI responds within 10 seconds
- [ ] Response uses actual company name
- [ ] NO generic responses like "the company"
- [ ] NO "Apliman" mentioned

---

#### Test 7.3: AI Chat with @User Mention
**Steps:**
1. In chat, type: `@`
2. Wait for user suggestion dropdown
3. Select: `Sarah Johnson`
4. Complete message: `@Sarah Johnson who is the best person to help with content strategy?`
5. Send

**Expected Result:**
- ‚úÖ @ triggers user dropdown in chat
- ‚úÖ Only shows company users
- ‚úÖ AI understands context about mentioned user
- ‚úÖ AI responds with relevant info

**Status:** ‚è≥ **NEEDS MANUAL TESTING** - **CRITICAL MENTION TEST**

**Verification Checklist:**
- [ ] @ triggers dropdown in chat
- [ ] Dropdown shows correct users
- [ ] Can mention user
- [ ] AI responds contextually

---

#### Test 7.4: AI Chat with /Task Reference
**Steps:**
1. In chat, type: `/`
2. Wait for task suggestion dropdown
3. Select: "Plan Q1 Social Media Campaign"
4. Complete message: `Give me a status update on /Plan Q1 Social Media Campaign`
5. Send

**Expected Result:**
- ‚úÖ / triggers task dropdown in chat
- ‚úÖ Shows company tasks
- ‚úÖ AI provides context about the task

**Status:** ‚è≥ **NEEDS MANUAL TESTING** - **CRITICAL REFERENCE TEST**

---

#### Test 7.5: AI Chat - Deep Analysis
**Steps:**
1. Toggle "Deep Analysis" mode (if available)
2. Ask: `Analyze our current task workload and suggest improvements`
3. Wait for response

**Expected Result:**
- ‚úÖ AI provides detailed analysis
- ‚úÖ Uses actual company data
- ‚úÖ Suggestions are relevant

**Status:** ‚è≥ **NEEDS MANUAL TESTING**

---

### ‚úÖ TEST SUITE 8: DUE DATE & "LATE" TAG

#### Test 8.1: Create Task with Past Due Date
**Steps:**
1. Create new task:
   ```
   Title: Overdue Test Task
   Description: Testing late tag functionality
   Due Date: [Yesterday's date]
   Workflow: Marketing Campaign Workflow
   Assigned To: John Smith
   ```
2. Submit
3. View task in list

**Expected Result:**
- ‚úÖ Task shows "Late" tag or indicator
- ‚úÖ Visual distinction (red color, icon, etc.)

**Status:** ‚è≥ **NEEDS MANUAL TESTING** - **CRITICAL FEATURE**

**Verification Checklist:**
- [ ] Task created with past due date
- [ ] "Late" tag visible
- [ ] Tag is red or otherwise highlighted
- [ ] Can filter by late tasks

---

#### Test 8.2: Task Becomes Late Over Time
**Steps:**
1. Create task with due date = today + 1 minute
2. Wait for 1-2 minutes
3. Refresh task list
4. Check if "Late" tag appears

**Expected Result:**
- ‚úÖ Task automatically marked as late when time passes
- ‚úÖ Real-time or on-refresh update

**Status:** ‚è≥ **NEEDS MANUAL TESTING**

**Note:** This tests if the system checks due dates dynamically

---

#### Test 8.3: View Late Tasks Filter
**Steps:**
1. Go to tasks page
2. Look for "Late Tasks" filter/view
3. Select it

**Expected Result:**
- ‚úÖ Shows only late tasks
- ‚úÖ Count displayed

**Status:** ‚è≥ **NEEDS MANUAL TESTING**

---

### ‚úÖ TEST SUITE 9: ANALYTICS - ALL SECTIONS

#### Test 9.1: Dashboard Analytics
**Steps:**
1. Navigate to Analytics page
2. Click "Dashboard" tab
3. Review all widgets/cards

**Expected Result:**
- ‚úÖ Tab loads successfully (NO 401 errors)
- ‚úÖ Shows task statistics
- ‚úÖ Shows workflow distribution
- ‚úÖ Shows completion rates
- ‚úÖ Charts render correctly

**Status:** ‚è≥ **NEEDS MANUAL TESTING** - **CRITICAL**

**Verification Checklist:**
- [ ] Dashboard tab accessible
- [ ] NO 401 errors
- [ ] Total tasks count displayed
- [ ] Active vs completed shown
- [ ] Phase distribution chart
- [ ] Workflow breakdown chart
- [ ] Data matches actual tasks

---

#### Test 9.2: Team Analytics
**Steps:**
1. Click "Team Analytics" tab
2. Review team performance data

**Expected Result:**
- ‚úÖ Tab loads successfully (NO 401 errors)
- ‚úÖ Shows all team members
- ‚úÖ Shows tasks per user
- ‚úÖ Shows completion rates per user
- ‚úÖ Can see user performance comparison

**Status:** ‚è≥ **NEEDS MANUAL TESTING** - **CRITICAL**

**Verification Checklist:**
- [ ] Team tab accessible
- [ ] NO 401 errors
- [ ] All users listed (John, Sarah, Mike)
- [ ] Task counts per user
- [ ] Completion percentages
- [ ] Performance charts
- [ ] Data accurate

---

#### Test 9.3: Task Analytics
**Steps:**
1. Click "Task Analytics" tab
2. Review task metrics

**Expected Result:**
- ‚úÖ Tab loads successfully (NO 401 errors)
- ‚úÖ Shows task breakdown by type
- ‚úÖ Shows task breakdown by priority
- ‚úÖ Shows task breakdown by status
- ‚úÖ Charts and metrics accurate

**Status:** ‚è≥ **NEEDS MANUAL TESTING** - **CRITICAL**

**Verification Checklist:**
- [ ] Task Analytics tab accessible
- [ ] NO 401 errors
- [ ] Task type breakdown
- [ ] Priority distribution
- [ ] Status distribution
- [ ] Timeline/trend charts
- [ ] Export functionality (if available)

---

#### Test 9.4: User (Personal) Analytics
**Steps:**
1. Navigate to User Analytics or Profile ‚Üí Analytics
2. Review personal statistics

**Expected Result:**
- ‚úÖ Shows current user's stats
- ‚úÖ Tasks assigned to me
- ‚úÖ Tasks completed by me
- ‚úÖ Personal performance metrics

**Status:** ‚è≥ **NEEDS MANUAL TESTING**

**Verification Checklist:**
- [ ] Personal analytics visible
- [ ] Shows only my tasks
- [ ] Completion rate accurate
- [ ] Time period filters work

---

#### Test 9.5: Analytics Time Range Filters
**Steps:**
1. On any analytics tab
2. Change time range: Today ‚Üí Week ‚Üí Month ‚Üí Year
3. Verify data updates

**Expected Result:**
- ‚úÖ Data filters by selected range
- ‚úÖ Charts update accordingly

**Status:** ‚è≥ **NEEDS MANUAL TESTING**

---

### ‚úÖ TEST SUITE 10: PROFILE MANAGEMENT

#### Test 10.1: View Profile
**Steps:**
1. Click on user avatar/name
2. Select "Profile" or navigate to profile page
3. Review profile information

**Expected Result:**
- ‚úÖ Shows current user details
- ‚úÖ Name, email, role, position displayed
- ‚úÖ Company affiliation shown

**Status:** ‚è≥ **NEEDS MANUAL TESTING**

---

#### Test 10.2: Edit Profile
**Steps:**
1. Click "Edit Profile" button
2. Change:
   ```
   Name: [New name]
   Position: [New position]
   ```
3. Save changes

**Expected Result:**
- ‚úÖ Changes save successfully
- ‚úÖ Updated info displays everywhere
- ‚úÖ Header/nav shows new name

**Status:** ‚è≥ **NEEDS MANUAL TESTING**

**Verification Checklist:**
- [ ] Can edit profile
- [ ] Changes save
- [ ] Changes reflect immediately
- [ ] Name updated in:
  - [ ] Header
  - [ ] Task assignments
  - [ ] Comments
  - [ ] @mentions

---

#### Test 10.3: Change Password
**Steps:**
1. In profile, find "Change Password"
2. Fill form:
   ```
   Old Password: [current]
   New Password: NewPass123!
   Confirm: NewPass123!
   ```
3. Submit
4. Logout and login with new password

**Expected Result:**
- ‚úÖ Password changes successfully
- ‚úÖ Can login with new password
- ‚úÖ Cannot login with old password

**Status:** ‚è≥ **NEEDS MANUAL TESTING**

---

### ‚úÖ TEST SUITE 11: KNOWLEDGE SOURCES

#### Test 11.1: View Knowledge Sources
**Steps:**
1. Navigate to Knowledge Sources page
2. Review existing sources (if any)

**Expected Result:**
- ‚úÖ Page loads successfully
- ‚úÖ Shows company's knowledge sources only
- ‚úÖ Does NOT show other companies' sources

**Status:** ‚è≥ **NEEDS MANUAL TESTING**

---

#### Test 11.2: Add COMPANY Knowledge Source
**Steps:**
1. Click "Add Knowledge Source"
2. Fill form:
   ```
   Name: About [Your Company Name]
   Type: COMPANY
   Description: Official company information
   Content: 
   [Your Company Name] is a leading provider of innovative solutions...
   [Add 2-3 paragraphs about the company]
   
   OR
   
   URL: https://yourcompany.com/about
   ```
3. Save

**Expected Result:**
- ‚úÖ Knowledge source created
- ‚úÖ Type = COMPANY
- ‚úÖ Active by default

**Status:** ‚è≥ **NEEDS MANUAL TESTING**

**Verification Checklist:**
- [ ] Source created successfully
- [ ] Appears in list
- [ ] Type is COMPANY
- [ ] isActive = true
- [ ] AI can use this source

---

#### Test 11.3: Add COMPETITOR Knowledge Source
**Steps:**
1. Add another knowledge source:
   ```
   Name: Competitor Analysis - CompetitorX
   Type: COMPETITOR
   Description: Key competitor information
   Content: CompetitorX focuses on... [add details]
   OR
   URL: https://competitorx.com
   ```
2. Save

**Expected Result:**
- ‚úÖ Competitor source created
- ‚úÖ Type = COMPETITOR

**Status:** ‚è≥ **NEEDS MANUAL TESTING**

---

#### Test 11.4: Scrape URL Knowledge Source
**Steps:**
1. Add knowledge source with URL:
   ```
   Name: Company Blog - Latest Updates
   Type: COMPANY
   URL: https://yourcompany.com/blog
   Description: Latest blog posts and updates
   ```
2. Save
3. Click "Scrape Now" button (if available)
4. Wait for scraping to complete

**Expected Result:**
- ‚úÖ Scraping initiates
- ‚úÖ Content extracted from URL
- ‚úÖ Content stored in knowledge source
- ‚úÖ AI can use scraped content

**Status:** ‚è≥ **NEEDS MANUAL TESTING**

**Verification Checklist:**
- [ ] Scrape button visible
- [ ] Scraping starts (loading indicator)
- [ ] Scraping completes
- [ ] Content preview shows scraped data
- [ ] Last scraped timestamp updated

---

#### Test 11.5: Scrape All Sources
**Steps:**
1. If "Scrape All" button exists, click it
2. Wait for all URL sources to be scraped
3. Verify all updated

**Expected Result:**
- ‚úÖ All URL sources scraped
- ‚úÖ Timestamps updated

**Status:** ‚è≥ **NEEDS MANUAL TESTING**

---

#### Test 11.6: AI Uses Knowledge Sources
**Steps:**
1. After adding knowledge sources
2. Open ApliChat
3. Ask: `Tell me about our company's mission`
4. Wait for response

**Expected Result:**
- ‚úÖ AI response includes info from knowledge sources
- ‚úÖ More detailed than without knowledge sources
- ‚úÖ Uses company-specific information

**Status:** ‚è≥ **NEEDS MANUAL TESTING** - **CRITICAL AI TEST**

**Verification Checklist:**
- [ ] AI accesses knowledge sources
- [ ] Response is more informed
- [ ] Uses company-specific details
- [ ] Does NOT use competitor info inappropriately

---

#### Test 11.7: Edit Knowledge Source
**Steps:**
1. Click Edit on a knowledge source
2. Modify content/URL
3. Save

**Expected Result:**
- ‚úÖ Changes save successfully
- ‚úÖ AI uses updated information

**Status:** ‚è≥ **NEEDS MANUAL TESTING**

---

#### Test 11.8: Delete Knowledge Source
**Steps:**
1. Click Delete on a knowledge source
2. Confirm deletion
3. Verify removed from list

**Expected Result:**
- ‚úÖ Source deleted
- ‚úÖ AI no longer uses that source

**Status:** ‚è≥ **NEEDS MANUAL TESTING**

---

#### Test 11.9: Toggle Knowledge Source Active/Inactive
**Steps:**
1. Find toggle/switch on knowledge source
2. Toggle to Inactive
3. Test if AI still uses it (should NOT)
4. Toggle back to Active

**Expected Result:**
- ‚úÖ Can disable/enable sources
- ‚úÖ Inactive sources not used by AI
- ‚úÖ Active sources used by AI

**Status:** ‚è≥ **NEEDS MANUAL TESTING**

---

## üìä COMPREHENSIVE TEST RESULTS SUMMARY

### Test Execution Status

| Test Suite | Total Tests | Status | Critical |
|------------|-------------|--------|----------|
| User Management | 3 | ‚è≥ Pending | No |
| Workflow Creation | 2 | ‚è≥ Pending | No |
| Task Creation | 3 | ‚è≥ Pending | ‚úÖ YES (AI) |
| Task Comments | 4 | ‚è≥ Pending | ‚úÖ YES (@/) |
| Image Upload | 3 | ‚è≥ Pending | No |
| Subtask Management | 4 | ‚è≥ Pending | No |
| AI Chat (@mentions) | 5 | ‚è≥ Pending | ‚úÖ YES |
| Due Date & Late Tag | 3 | ‚è≥ Pending | ‚úÖ YES |
| Analytics | 5 | ‚è≥ Pending | ‚úÖ YES |
| Profile Management | 3 | ‚è≥ Pending | No |
| Knowledge Sources | 9 | ‚è≥ Pending | ‚úÖ YES (AI) |
| **TOTAL** | **44** | **Pending** | **20 Critical** |

---

## üéØ CRITICAL FEATURES TO VERIFY

### **HIGHEST PRIORITY:**
1. ‚úÖ **AI Task Generation** - Does AI generate content without 401 errors?
2. ‚úÖ **AI Subtask Generation** - Do subtasks auto-generate?
3. ‚úÖ **AI Chat with Company Name** - Does AI say company name, not "Apliman"?
4. ‚úÖ **@Mentions in Comments** - Do @ mentions work in task comments?
5. ‚úÖ **@Mentions in AI Chat** - Do @ mentions work in ApliChat?
6. ‚úÖ **/ Task References** - Do / references work?
7. ‚úÖ **All 3 Analytics Tabs** - Can COMPANY_ADMIN access all tabs?
8. ‚úÖ **Late Tag** - Do overdue tasks show "Late" indicator?
9. ‚úÖ **Knowledge Sources & AI** - Does AI use knowledge sources?
10. ‚úÖ **Scraping** - Does URL scraping work?

---

## üìã TESTING WORKFLOW

### **Suggested Testing Order:**

1. **Setup Phase** (15 min)
   - Create 3 users (Admin, 2 Employees)
   - Create 2 workflows
   
2. **Core Features** (20 min)
   - Create tasks (manual + AI)
   - Test AI generation
   - Test subtask generation
   
3. **Comments & Mentions** (15 min)
   - Add comments
   - Test @mentions
   - Test /task references
   - Upload images
   
4. **AI Chat** (10 min)
   - Test basic chat
   - Test company name response
   - Test @mentions in chat
   - Test /task references in chat
   
5. **Due Dates** (5 min)
   - Create task with past due date
   - Verify "Late" tag
   
6. **Analytics** (10 min)
   - Test all 3 tabs
   - Verify NO 401 errors
   - Check data accuracy
   
7. **Knowledge Sources** (15 min)
   - Add COMPANY source
   - Add COMPETITOR source
   - Test scraping
   - Verify AI uses sources
   
8. **Profile** (5 min)
   - Edit profile
   - Change password

**Total Estimated Time:** ~90 minutes for complete testing

---

## ‚úÖ SUCCESS CRITERIA

### **Tests PASS if:**
- ‚úÖ NO 401 errors in console
- ‚úÖ AI generates content successfully
- ‚úÖ AI uses actual company name (not "Apliman")
- ‚úÖ @mentions work in comments and chat
- ‚úÖ /task references work
- ‚úÖ All analytics tabs accessible
- ‚úÖ Late tags appear on overdue tasks
- ‚úÖ Knowledge sources can be added and scraped
- ‚úÖ AI uses knowledge sources in responses
- ‚úÖ Images upload successfully
- ‚úÖ Subtasks auto-generate and are manageable

### **Tests FAIL if:**
- ‚ùå Any 401 errors appear
- ‚ùå AI generation fails or times out
- ‚ùå AI says "Apliman" instead of company name
- ‚ùå @mentions don't trigger dropdowns
- ‚ùå Analytics tabs show 403 errors
- ‚ùå Late tags don't appear
- ‚ùå Scraping fails
- ‚ùå AI doesn't use knowledge sources

---

## üêõ ISSUES TO DOCUMENT

For each failed test, document:
```markdown
### Issue: [Title]
**Test ID:** [Test number]
**Severity:** Critical / Major / Minor
**Status:** Open

**Description:**
[What went wrong]

**Steps to Reproduce:**
1. [Step 1]
2. [Step 2]

**Expected:** [What should happen]
**Actual:** [What happened]

**Console Errors:**
```
[Paste errors]
```

**Screenshots:**
[Attach]
```

---

## üìù NOTES FOR TESTER

### Before Starting:
- ‚úÖ Backend deployed with latest fixes
- ‚úÖ Frontend deployed with latest fixes
- ‚úÖ Have Google Gemini API key
- ‚úÖ Browser DevTools open (F12)
- ‚úÖ Console tab visible
- ‚úÖ Network tab visible (check 401 errors)

### During Testing:
- Take screenshots of successes AND failures
- Note exact error messages
- Check console after EVERY action
- Document response times (slow = issue)
- Test on both desktop and mobile (if time)

### After Testing:
- Fill in all Status fields (‚úÖ Pass, ‚ùå Fail, ‚ö†Ô∏è Warning)
- Calculate pass rate
- Prioritize bugs (Critical first)
- Report findings

---

## üéâ READY TO TEST!

This comprehensive test covers all user-facing features you requested:
- ‚úÖ User creation
- ‚úÖ Workflow creation
- ‚úÖ Task creation
- ‚úÖ AI generation (tasks, subtasks)
- ‚úÖ Comments with @mentions and /references
- ‚úÖ Image upload
- ‚úÖ Subtask management
- ‚úÖ AI chat with mentions
- ‚úÖ Due date and "Late" tags
- ‚úÖ All analytics sections
- ‚úÖ Profile management
- ‚úÖ Knowledge sources and scraping

**Start testing and mark each test as Pass/Fail!** üß™


